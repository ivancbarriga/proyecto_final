{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "dataTesting = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento \n",
    "#variable de interes\n",
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])\n",
    "\n",
    "# Se combina el título de la película con la trama\n",
    "dataTraining_2 = dataTraining.copy()\n",
    "dataTraining_2['title_plot'] = dataTraining_2['title'] + ' - ' + dataTraining_2['plot']\n",
    "dataTraining_2.drop(columns=['title','plot','rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "#Encoder\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import tensorflow_hub as hub\n",
    "import seaborn as sns\n",
    "\n",
    "# Importación el módulo TF Hub del Universal Sentence Encoder\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Codificación de las frases anteriormente definidas con la libreria tensorflow\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    sentences_embeddings = session.run(embed(dataTraining_2['title_plot']))\n",
    "\n",
    "#df con encoder y el indice de fila\n",
    "x_embed = pd.DataFrame(sentences_embeddings)\n",
    "x_embed.index = dataTraining_2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PostProcesamiento\n",
    "#Se adiciona el año de la película a la matriz de embedding\n",
    "dataTraining_3 = pd.concat([dataTraining_2, x_embed], axis=1)\n",
    "dataTraining_3.drop(columns=['title_plot', 'genres'], inplace=True)\n",
    "\n",
    "# Se estandariza la data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "dataTraining_3 = scaler.fit_transform(dataTraining_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separa la data en conjunto de entrenamiento y conjunto de validación\n",
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(dataTraining_3, y_genres, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b2e1d2e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías para la implementación de la red neuronal\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "\n",
    "dims = dataTraining_3.shape[1]\n",
    "var_out = y_genres.shape[1]\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()  \n",
    "model.add(Dense(512, input_shape=(dims,), activation='sigmoid'))\n",
    "model.add(Dense(var_out, activation='sigmoid'))\n",
    "\n",
    "# Definición de función de perdida con parámetros definidos en la función nn_model_params\n",
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Definición de la función EarlyStopping con parámetro definido en la función nn_model_params\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 10)\n",
    "\n",
    "# Entrenamiento de la red neuronal con parámetros definidos en la función nn_model_params\n",
    "model.fit(X_train, y_train_genres, \n",
    "          validation_data = (X_test, y_test_genres),\n",
    "          epochs=6,\n",
    "          batch_size=64,\n",
    "          callbacks=[early_stopping],\n",
    "          verbose=0 \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proy_final/scaler.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Exportar modelo a archivo binario .pkl\n",
    "joblib.dump(scaler, 'proy_final/scaler.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Guardado!\n"
     ]
    }
   ],
   "source": [
    "# serializar el modelo a JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"proy_final/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serializar los pesos a HDF5\n",
    "model.save_weights(\"proy_final/model.h5\")\n",
    "print(\"Modelo Guardado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado modelo desde disco.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# cargar json y crear el modelo\n",
    "json_file = open('proy_final/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# cargar pesos al nuevo modelo\n",
    "loaded_model.load_weights(\"proy_final/model.h5\")\n",
    "print(\"Cargado modelo desde disco.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo de clasificación\n",
    "y_pred_genres = loaded_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014281001448131"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Impresión del desempeño del modelo\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento para nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para predecir en la base de datos de test de kaggle hay que hacer el mismo tratamiento:\n",
    "\n",
    "dataTesting_2 = dataTesting.copy()\n",
    "dataTesting_2['title_plot'] = dataTesting_2['title'] + ' - ' + dataTesting_2['plot']\n",
    "dataTesting_2.drop(columns=['title','plot'], inplace=True)\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# Importación el módulo TF Hub del Universal Sentence Encoder\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# Codificación de las frases anteriormente definidas con la libreria tensorflow\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    sentences_embeddings_2 = session.run(embed(dataTesting_2['title_plot']))\n",
    "\n",
    "x_test_embed = pd.DataFrame(sentences_embeddings_2)\n",
    "x_test_embed.index = dataTesting_2.index\n",
    "\n",
    "dataTesting_3 = pd.concat([dataTesting_2, x_test_embed], axis=1)\n",
    "dataTesting_3.drop(columns=['title_plot'], inplace=True)\n",
    "dataTesting_3 = scaler.transform(dataTesting_3)\n",
    "dataTesting_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataTesting_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred_genres_2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mdataTesting_3\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataTesting_3' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_genres_2 = model.predict(dataTesting_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "res = pd.DataFrame(y_pred_genres_2, index=dataTesting.index, columns=cols)\n",
    "res.to_csv('pred_calib_param_3.csv', index_label='ID')\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: lo entreno otra vez uno diferente, para validar que la infraestructura del anterior no incide en el problema de guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Definición red neuronal con la función Sequential()\n",
    "model2 = Sequential()\n",
    "    \n",
    "# Definición de las capas de la red con el número de neuronas y la función de activación definidos en la función nn_model_params\n",
    "model2.add(Dense(512, input_shape=(dims,), activation='sigmoid'))\n",
    "model2.add(Dense(var_out, activation='sigmoid'))\n",
    "\n",
    "# Definición de función de perdida con parámetros definidos en la función nn_model_params\n",
    "model2.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Definición de la función EarlyStopping con parámetro definido en la función nn_model_params\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 10)\n",
    "\n",
    "# Entrenamiento de la red neuronal con parámetros definidos en la función nn_model_params\n",
    "model2.fit(X_train, y_train_genres,\n",
    "          validation_data = (X_test, y_test_genres),\n",
    "          epochs=20,\n",
    "          batch_size=64,\n",
    "          callbacks=[early_stopping, PlotLossesKeras()],\n",
    "          verbose=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# guardar el modelo\n",
    "#joblib.dump(model, 'API/modelo_red_neuronal.pkl', compress=3)\n",
    "joblib.dump(scaler, 'model_deploy/scaler.pkl', compress=3)\n",
    "\n",
    "#tf.saved_model.save(model, 'API/modelo_red_neuronal3')\n",
    "\n",
    "model2.save('model_deploy/modelo_red_neuronal_h5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "modelo_cargado = load_model('API/modelo_red_neuronal_h5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cargado.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTesting.loc[1]['plot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datos = pd.DataFrame({'year': 1999, 'title': 'Message in a Bottle', 'plot': \"who meets by fate ,  shall be sealed by fate .  theresa osborne is running along the beach when she stumbles upon a bottle washed up on the shore .  inside is a message ,  reading the letter she feels so moved and yet she felt as if she has violated someone ' s thoughts .  in love with a man she has never met ,  theresa tracks down the author of the letter to a small town in wilmington ,  two lovers with crossed paths .  but yet one can ' t let go of their past .\"\n",
    "                        }, index=[0])\n",
    "df_datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from API.proyecto2_deployment import transformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = transformar(df_datos)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask_restx import Api, Resource, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "api = Api(\n",
    "    app, \n",
    "    version='1.0', \n",
    "    title='Clasificación de género de películas',\n",
    "    description='Clasificación de género de películas')\n",
    "\n",
    "ns = api.namespace('predict', \n",
    "     description='Predicción géneros de la película')\n",
    "\n",
    "parser = api.parser()\n",
    "\n",
    "parser.add_argument(\n",
    "    'year', \n",
    "    type=int, \n",
    "    required=True, \n",
    "    help='Año del lanzamiento de la película', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'title', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Nombre de la película', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'plot', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Trama de la película', \n",
    "    location='args')\n",
    "\n",
    "resource_fields = api.model('Resource', {\n",
    "    'result': fields.String,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ns.route('/')\n",
    "class PrediccionApi(Resource):\n",
    "\n",
    "    @api.doc(parser=parser)\n",
    "    @api.marshal_with(resource_fields)\n",
    "    def get(self):\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        return {\n",
    "         \"result\": transformar(args)  \n",
    "        }, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(debug=True, use_reloader=False, host='0.0.0.0', port=8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze '/requirem.txt'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
